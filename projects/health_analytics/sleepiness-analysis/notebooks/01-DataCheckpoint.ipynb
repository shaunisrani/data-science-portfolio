{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Arav Vyawahare: Background research, Data, Conceptualization, Writing – original draft, Writing – review & editing\n",
    "- Jude Gamba: Background research, Ethics, Conceptualization, Writing – original draft, Writing – review & editing\n",
    "- Shaun Israni: Background and Ethics, Writing – original draft, Writing – review & editing\n",
    "- Colin: Background, Research, and Prior Work, Conceptualization, Writing – original draft, Writing – review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent can sleep quality metrics (sleep duration, sleep fragmentation, REM latency, and sleep efficiency) predict the risk of developing neurodegenerative diseases such as Alzheimer’s disease, Parkinson's disease, and dementia over time, accounting for demographic and lifestyle variables?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sleep is one of the most important and necessary parts of our everyday routine, playing a critical role in helping us maintain cognitive function, brain health, memory, mood, emotional regulation, and overall well-being. It plays a vital role in the human health as a whole, allowing the brain to reset itself, remove accumulated toxic byproducts, and adjust neurotransmitter levels, enhancing learning by forming new neural connections and problem-solving abilities. \n",
    "\n",
    "An emerging concern associated with sleep quality is the link between sleep and neurodegeneration, the loss of neurons connected with various behavioral impairments. More generally, neurodegeneration can be seen as the progressive loss of neurons and functionalities. Sleep and sleep quality has become increasingly intertwined and linked to neurodegenerative diseases because of its large impact on brain functionality and regulation. For example, analyses have found that insomnia elevates the risk of all-cause dementia, especially when occurring with a major depressive disorder (MDD). This leads to our main research question: How much of an impact does sleep quality have on the likelihood of developing neurodegenerative disease or other similar health effects? According to studies, having a persistently short sleep duration at ages 50 to 70 compared to persistent normal sleep duration was associated with a 30% risk increase in dementia. This was independent of sociodemographic, behavioural, cardiometabolic, and mental health factors as well. \n",
    "\n",
    "The amount of prior work done on this topic of sleep and neurodegeneration is pretty extensive as studies on our sleep and sleeping habits have a long and storied history. In the past few decades, researchers have made extensive progress on the study of sleep and its effects on all parts of the human body. Recently, researchers have recognized and identified sleep quality as a potential risk factor and symptom of neurodegeneration. However, many aspects of this relationship are still being studied presently and new data and relationships are being found.\n",
    "\n",
    "Source 1 <a name=\"cite_note-1\"></a> [^](#cite_ref-1)\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC4651462 –\n",
    "“More specifically, when one sleeps, the brain reorganizes and recharges itself, and removes toxic waste byproducts which have accumulated throughout the day.”\n",
    "\n",
    "In this research study they compiled multiple studies and information regarding the correlations between the brain and sleep and explained the aspects of sleep that impact our health. They explained the different specific processes that occur during our sleep and the tangible consequences.\n",
    "\n",
    "Source 2 <a name=\"cite_note-2\"></a> [^](#cite_ref-2)\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC7593848 – \n",
    "“Neurodegeneration is defined as the loss of neurons in association with behavioural impairments.”\n",
    "\n",
    "This source studied the impact of sleep disruptions on brain health and functionality. They used mice and animal models, helping them relate chronic sleep loss to negative impacts on the brain including neurodegeneration and increased risk to neurodegenerative disease.\n",
    "\n",
    "Source 3 <a name=\"cite_note-3\"></a> [^](#cite_ref-3)\n",
    "https://www.mdpi.com/2077-0383/14/19/7119 – \n",
    "“indicates that insomnia significantly elevates the risk of all-cause dementia, particularly when co-occurring with major depressive disorder (MDD), which amplifies this association”\n",
    "\n",
    "This study researches the relationship between neurodegenerative diseases (more specifically Dementia) and sleep disorders. They discovered a bidirectional relationship where they both can impact each other and facilitate even more health issues.\n",
    "\n",
    "Source 4 <a name=\"cite_note-4\"></a> [^](#cite_ref-4)\n",
    "https://www.nature.com/articles/s41467-021-22354-2  —\n",
    "“Persistent short sleep duration at age 50, 60, and 70 compared to persistent normal sleep duration was also associated with a 30% increased dementia risk independently of sociodemographic, behavioural, cardiometabolic, and mental health factors.”\n",
    "\n",
    "This source researched the different relationships between sleep duration and the occurrence of dementia in older folks. They determined that there was a higher dementia risk associated with a sleep duration of six hours or less at age 50 and 60.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re predicting that there will be a strong correlation between sleep disruption, quality, and deprivation and neurodegenerative diseases such as Alzheimer’s, Parkinson’s, and dementia. Specifically, we hypothesize that observed negative changes in sleep metrics will have adverse effects on the prevalence of blood based bio markers, lewy body counts and cognitive assessment scores (i.e Montreal Cognitive Assessment, Mini Mental State Examination, UPDRS, etc)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1: Parkinson’s Dataset \n",
    "  - Dataset Name: Parkinson's Progression Markers Initiative\n",
    "  - Link to the dataset: https://ida.loni.usc.edu/home/projectPage.jsp?project=PPMI\n",
    "  - Number of observations: 6138\n",
    "  - Number of variables: 84\n",
    "  - Description of the variables most relevant to this project: \n",
    "\n",
    "\t-> Demographics: \n",
    "  - PATNO = The patient number that uniquely identifies each patient.\n",
    "\t- ENROLL_AGE = The age at which the patient enrolled into the program.\n",
    "\n",
    "\t-> Patient Health and Genetics: \n",
    "  - ENRLPINK1\tENRLPRKN\tENRLSRDC\tENRLNORM\tENRLOTHGV\tENRLHPSM\tENRLRBD\tENRLLRRK2\tENRLSNCA\tENRLGBA → These variables are either gene mutations or underlying medical conditions that could contribute to the later development of Parkinson’s disease. \n",
    "\n",
    "\t-> Patient Sleep and Quality Metrics: \n",
    "- ESS1\tSitting and reading\t\n",
    "- ESS2\tWatching TV\t\n",
    "- ESS3\tSitting inactive in a public place (e.g., theater, meeting)\t\n",
    "- ESS4\tAs a passenger in a car for an hour without a break\t\n",
    "- ESS5\tLying down to rest in the afternoon when circumstances permit\t\n",
    "- ESS6\tSitting and talking to someone\t\n",
    "- ESS7\tSitting quietly after a lunch without alcohol\t\n",
    "- ESS8\tIn a car, while stopped for a few minutes in traffic\t\n",
    "- These variables are a part of the EPWORTH Sleepiness Scale which is a - numerical measure of daytime sleepiness. This scale (range from 0-3)  tells us how likely a person is to doze off or fall asleep in different everyday situations.\n",
    "- SLPDSTRB = General sleep disturbances, DRMVIVID = reports of the patient having vivid dreams (associated with RBD – rem sleep behavior disorder), MVAWAKEN = movements wakes up patients\n",
    "\n",
    "\n",
    "- Descriptions of any shortcomings this dataset has with respect to the project ---- \n",
    "The dataset contains a large amount of data about sleep metrics, patient information and many other useful biological metrics that may aid in our analysis, however, the amount of data can also be detrimental. Many of tabular data within this dataset requires rigorous cleaning and many columns are irrelevant for the reasearch question we are targetting. The most difficult process will be to wrangle all the neccessary relevant data without misinterpreting the results.\n",
    "\n",
    "\n",
    "-Dataset 2: NACC Alzheimer’s x Sleep Factors\n",
    "  - Dataset Name:  Alzheimer’s from NACC: UDS Data Summary Tables\n",
    "  - Link to the dataset: https://naccdata.org/ \n",
    "  - Number of observations: 127759\n",
    "  - Number of variables: 47\n",
    "  - Description of the Variables Most Relevant to This Project:\n",
    "    - Specific variables currently in the cleaned analysis_data dataframe that will be used to test our hypothesis are included here. \n",
    "    - Mayo Sleep Questionnaire + SCOPA-sleep = very detailed and validated surveys\n",
    "- A. Independent Variables: Sleep Quality & Disruption \n",
    "    - NITE (Nighttime Behaviors): Assesses sleep fragmentation, such as awakening the bed partner, rising too early, or excessive napping.\n",
    "    - HYPOSOM (Insomnia): Indicates the presence of hyposomnia or insomnia.\n",
    "    - RBD (REM Sleep Behavior Disorder): Whether participants appear to act out dreams.\n",
    "    - LBSPDRM (Dream Enactment): From questionnaire, asking if the participant has been told they \"act out their dreams\" (punching, flailing) while sleeping -> key predictor for Lewy Body pathology. \n",
    "    - CONSFALL & CONSWKOF (SCOPA-Sleep): Measuring difficulty falling asleep and waking up too often, which serve as proxies/in relation for sleep latency and fragmentation.\n",
    "    - CODSAWDY (Daytime Sleepiness: Measures excessive daytime sleepiness, often a consequence of poor nighttime sleep efficiency.\n",
    "- B. Dependent Variables: Neurodegenerative Outcomes\n",
    "    - NACCETPR (Primary Diagnosis): Clinician's judgment of the primary cause of cognitive impairment. In the dataframe given it compares Alzheimer's (Code 1) vs. Lewy Body/Parkinson's (Code 2) vs. Normal Controls (Code 88).\n",
    "    - NACCALZD: A binary indicator (Yes/No) for the presence of Alzheimer's Disease etiology.\n",
    "    - NACCLBDS: A binary indicator for Lewy Body Dementia Syndrome.\n",
    "    - NACCMMSE & NACCMOCA: Standardized cognitive test scores, where lower scores indicate greater cognitive decline.\n",
    "    - NACCACSF, NACCPCSF, NACCTCSF: Cerebrospinal fluid biomarkers for Amyloid Beta, Phosphorylated Tau, and Total Tau. These are the \"gold standard\" biological indicators of Alzheimer's pathology.\n",
    "    - NPLBOD: Neuropathology findings from autopsy indicating the actual presence of Lewy Bodies in the brain.\n",
    "- C. Covariates\n",
    "    - NACCAPOE: Indicates presence of the APOE ε4 allele, the strongest genetic risk factor for Alzheimer's.\n",
    "    - CVHATT & DIABETES: Cardiovascular health history and diabetes status, which are known comorbidities for both sleep apnea and dementia.\n",
    "- Descriptions of any shortcomings this dataset has with respect to the project: \n",
    "    - While the NACC dataset from the UPS with NP and Genetics plus FTLD and LBD modules is one of the largest datasets of its kind, it has specific limitations regarding objective sleep measures and ideas like sleep architecture. \n",
    "1. Lack of Objective Sleep Data\n",
    "    - Our hypothesis requests explicitly with the context for Actigraphy-derived data, including total sleep time, sleep fragmentation index, and polysomnography measures\n",
    "In reality, our NACC dataset is primarily clinical and questionnaire-based, which makes variables like NITE, LBSPDRM, and CONSFALL that are subjective reports from the patient or bed partner to be less accurate. \n",
    "While there’s a variable indicating if a polysomnogram was done (LBOPOLYS in the LBD module), the dataset we have doesn’t contain the raw granular data files like sleep architecture graphs or ms-level fragmentation indices to give the most specific sleep data records. \n",
    "Thus, we are analyzing more perceived sleep quality and observed behaviors on the same depth of variables/factors though, not objective physiological sleep architecture\n",
    "2. High Missingness in Detailed Sleep Metrics\n",
    "    - High quality sleep questions (Mayo Sleep Questionnaire, SCOPA survey) located in the LBD module are typically only administered to patients suspected of having Lewy Body Dementia or Parkinson’s. \n",
    "This means that the “normal controls” and “Alzheimer's” patients will largely have NA (missing data) for variables like LBSPDRM and CONSFALL.\n",
    "Thus, we may encounter difficulty comparing detailed sleep symptoms between the LBD group and the AD/Control groups because the AD/Control groups simply weren't asked those specific questions, and we may have to rely on the coarser NITE variable for cross-group comparison.\n",
    "3. Biomarker Sparse Data\n",
    "    - Our hypothesis also looks for the effects on blood-based and CSF biomarkers as included in our dataset. \n",
    "The CSF collection (NACCACSF, etc.) is invasive and optional; consequently, a large percentage of rows in our dataset analysis_data have NA for these biomarkers.\n",
    "The sample size for the biomarker portion of my analysis may be significantly smaller than the sample size for the clinical diagnosis portion, which could skew and frame analysis in inhibiting ways\n",
    "- Additionally, there are also covariates in many demographic and general health variables (age, sex, race, smoking in last 30 days, alcohol abuse history) as well as other biomarker variables (APOe genotype, number of APOE e4 alleles, diagnosis of Lewy Body pathology) that are confounding and we will have to determine how to control for those covariates so that we can clearly see the effect of sleep quality on alzheimer’s and parkinson’s through this complexity. Additionally, since the dataset still includes patients with Frontotemporal Dementia (FTD) (we removed those where FTD is the primary cause) and those biomarkers and sleep signatures greatly differ than those for identifications of people with AD, PD, and LBD, including FTD patients might make the data a little more messy when trying to find a clear signal between sleep and AD/PD biomarkers because of the minor presence of other biomarkers that some patients might have, but it might also strengthen and hone the analysis too through this complexity. Additionally, a good portion of the sleep data comes from questionnaires and surveys (though verified, detailed, and reputable) such as the SCOPA-survey and the Dream Enactment Mayo Sleep Questionnaire, which could cause less accurate results and other potential issues as listed above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: WE ARE USING NON_PUBLIC DATASETS SO THESE CODE CELLS DO NOT APPLY TO US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://www.kaggle.com/code/probristy099/parkinson-s-dataset/input', 'filename':'parkinsons_disease_data.csv'},\n",
    "    { 'url': 'https://www.kaggle.com/datasets/rabieelkharoua/alzheimers-disease-dataset', 'filename':'alzheimers_disease_data.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parkinson's + Alzheimer's Disease Studies: Datasets 1 and 2\n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. \n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "- Dataset 1: \n",
    "This dataset combines clinical, metabolomic, and sleep-related information for individuals in various Parkinson’s disease (PD) related cohorts. \n",
    "\n",
    "The metabolomic data file contains thousands of rows, each representing a single measured feature detailing the testing and result for a single patient. Each row includes contains plasma LC/MS measurements from individuals enrolled as Parkinson’s disease patients, prodromal participants, or healthy controls. For each participant, multiple features are measured using untargeted mass spectrometry, and each feature is defined by TESTNAME. The values in the column TESTNAME take the form MZxxx.xx_RTyyy.yy_mmm where MZxxx.xx indicates a mass to charge ratio of xxx.xx, RTyyy.yy is the retention time in seconds, and mmm indicates either positive or negative ionization mode. These molecular features capture many different types of chemicals that are important in neurodegenerative diseases. They include purines involved in energy and cell signaling, lipids linked to lysosomal function, molecules that reflect oxidative stress, markers of inflammation, and indicators of environmental or dietary exposures.\n",
    "\n",
    "The Participant Status dataset provides demographic and diagnostic information about each individual, including sex, cohort classification (e.g., Healthy Controls, Prodromal, SWEDD, Early Imaging, and Parkinson's Disease), and clinical visit numbers (e.g., V04). These identifiers allow researchers to link biomarker data with disease status, time points, and potential progression markers. The structured visit labels indicate tracking over time, which is helpful for studying early disease signals and development.\n",
    "\n",
    "The Epworth Sleepiness Scale (ESS) dataset measures daytime sleepiness across eight scenarios (e.g., sitting and reading, traveling in a car). Each item (ESS1–ESS8) is scored from 0 to 3, and the total ESS score ranges from 0 to 24. Higher values indicate increased daytime sleepiness, and scores >10 typically indicate excessive daytime sleepiness, which can be associated with neurological conditions such as PD (Parkinson's Disease) or REM sleep behavior disorder. The dataset also includes visit dates, baseline vs. later visits, and identifiers that allow linkage across the different files through PATNO (patient number).\n",
    "\n",
    "The REM Sleep Behavior Disorder (RBD) Questionnaire dataset adds another relevant sleep-related dimension. It measures the likelihood and severity of different sleep-related behaviors. More specifically, it measures how often people act out their dreams or lose normal muscle relaxation during REM sleep—problems that are common early signifiers of Parkinson’s disease. Each question reflects how frequent or severe these behaviors are, and higher scores mean stronger signs of possible RBD.\n",
    "\n",
    "- Dataset 2:\n",
    "    - This dataset is a processed subset of the National Alzheimer’s Coordinating Center (NACC) Uniform Data Set (UDS), containing 127,759 observations and 56 variables. It aggregates longitudinal clinical, genetic, and neuropathological data from Alzheimer’s Disease Centers across the US. The dataset tracks participants over time to monitor transitions from normal cognition to mild cognitive impairment (MCI) and dementia. It specifically combines general health information with specialized modules for Lewy Body Dementia (LBD) and Frontotemporal Lobar Degeneration (FTLD) to capture detailed sleep and motor symptoms. The population includes healthy controls, those with subjective cognitive decline, and patients diagnosed with Alzheimer’s Disease (AD), Parkinson’s Disease (PD), or Lewy Body Dementia (LBD).\n",
    "\n",
    "## Interpretation of What These Metrics Mean\n",
    "Dataset 1: \n",
    "\n",
    "Together, these metrics help researchers see whether patterns in a person's health (sleep, metabolic changes in blood) relate to Parkinson’s disease, early warning signs of the disease, or sleep problems. For example, if people with higher sleepiness scores (ESS) or stronger RBD symptoms show different metabolite patterns, it could suggest links between sleep disruption, metabolism, and early neurodegeneration. The visit labels and patient IDs let us track the same person over time, so changes in their metabolite levels and sleep levels may reflect disease progression or treatment effects. Because the dataset uses untargeted mass spectrometry, it captures thousands of raw features rather than only known metabolites, which can help uncover unexpected biological changes connected to both Parkinson’s disease and sleep dysfunction.\n",
    "\n",
    "Dataset 2: \n",
    "\n",
    "These metrics allow researchers to correlate sleep disturbances with specific neurodegenerative outcomes and cognitive decline. \n",
    "- Cognitive Performance (MMSE & MoCA):\n",
    "    - NACCMMSE (Mini-Mental State Exam): Measured on a scale of 0 to 30. In this dataset, the median is 28, indicating a generally cognitively healthy baseline for many, but values range down to 0. Generally, scores 24–30 indicate no impairment, 18–23 indicate mild impairment, and 0–17 indicate severe impairment.\n",
    "    - NACCMOCA (Montreal Cognitive Assessment): Also a 30-point scale but more sensitive to mild impairment. The dataset median is 25. Scores $\\ge$ 26 are considered normal.\n",
    "- Sleep Quality Indices:\n",
    "    - NITE (Nighttime Behaviors): A binary metric (0=Absent, 1=Present) from the NPI-Q. A value of 1 indicates the patient exhibits sleep fragmentation behaviors like awakening the bed partner, rising too early, or pacing at night.\n",
    "    - LBSPDRM (REM Sleep Behavior Disorder): A binary metric (0=No, 1=Yes) from the Mayo Sleep Questionnaire asking if the patient \"acts out their dreams\" (punching, flailing). A 1 is a strong prodromal predictor for Lewy Body pathology (Parkinson’s/LBD) rather than Alzheimer's.\n",
    "    - SCOPA-Sleep (CONSFALL, CONSWKOF): Ordinal scales ranging from 0 (Not at all) to 3 (A lot). Higher values indicate greater severity of sleep latency (trouble falling asleep) or fragmentation (waking too often).\n",
    "- Clinical Diagnosis (NACCETPR):\n",
    "    - A categorical variable representing the primary etiology of cognitive impairment. We filtered the data to focus on Code 1 (Alzheimer's Disease), Code 2 (Lewy Body Disease/Parkinson's), and Code 88 (Normal Controls/No impairment).\n",
    "- Biomarker Availability (NACCACSF):\n",
    "    - A binary flag (0/1) indicating whether cerebrospinal fluid (CSF) data for Amyloid Beta or Tau is available for the patient. A 1 indicates the presence of this \"gold standard\" biological data.\n",
    "\n",
    "- Data Cleaning and Processing\n",
    "The original raw dataset contained thousands of variables and \"junk codes\" specific to NACC entry protocols\n",
    "1. Missing Data Handling: NACC uses codes like -4 (Not available), 9 (Unknown), 8 (Not applicable), and 88 to represent missingness. We converted all occurrences of these integers into standard NA values to prevent skewing statistical calculations (e.g., treating a missing age as 999).\n",
    "2. Filtering: We filtered the dataset to exclude patients with Frontotemporal Dementia (FTD) as a primary cause, as their sleep/biomarker profiles differ significantly from our target AD/PD populations. We retained only rows where the Primary Diagnosis (NACCETPR) was Alzheimer's, Lewy Body/PD, or Normal.\n",
    "3. Type Conversion: Categorical variables (Sex, Race, Diagnosis) were converted from integers to factors to ensure proper grouping in analysis.\n",
    "\n",
    "## Potential Concerns and Limitations\n",
    "\n",
    "Dataset 1: \n",
    "\n",
    "A major concern is that the metabolomic dataset is enormous and unfiltered, containing hundreds of thousands of individual features. Untargeted metabolomics data often includes noise, redundant features, isotope/adduct peaks, or unidentified mass signals. Without preprocessing, apparent group differences may reflect technical variation rather than biological differences. \n",
    "\n",
    "Another concern is sample bias. The dataset appears to come from research volunteers enrolled in a PD study, which means participants may not represent the general population—volunteers are often healthier, more motivated, and more educated. PD participants may be recruited from specialized clinics, leading to diagnostic or socioeconomic biases. Furthermore, repeated visit data may not be complete for all patients, raising the possibility of missingness bias if individuals with more severe progression fail to return for later visits.\n",
    "\n",
    "Finally, ESS scores are self-reported and may be influenced by subjective factors such as mood, understanding of the questionnaire, or recall bias. Sleepiness also fluctuates with medication use, comorbid sleep disorders, or lifestyle factors not included in the dataset. As a result, ESS should be interpreted cautiously and ideally complemented with objective sleep measures.\n",
    "\n",
    "Dataset 2: \n",
    "\n",
    "A major concern is the extreme missingness in the detailed sleep and biomarker variables.\n",
    "\n",
    "- Systematic Missingness (MNAR): The detailed sleep metrics (like LBSPDRM and CONSFALL) are part of the LBD Module and In our summary statistics, LBSPDRM has 126,933 NAs out of 127,759 rows (>99% missing). This is because this module is typically only administered to patients already suspected of Parkinson's or LBD, which means that the \"Normal\" and \"Alzheimer's\" patients rarely have this data. This as a result makes our cross-group comparison difficult.\n",
    "\n",
    "- Biomarker Scarcity: Similarly, the biomarker availability flags (NACCACSF) have very low means (~0.05), indicating that only ~5% of participants underwent the invasive lumbar puncture required for CSF data.\n",
    "\n",
    "- Subjectivity: Variables like NITE are based on caregiver or patient reports, not objective actigraphy. Depression (DEPRS) and anxiety are confounding comorbidities/factors that can alter sleep independent of neurodegeneration, and these require careful statistical control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Merging Steps\n",
    "\n",
    "Step 1: Variable Selection and Initial Cleaning\n",
    "\n",
    "The code first loaded the three datasets and selected only the specified columns for processing. Outlier handling was performed on $\\text{ENROLL\\_AGE}$ by converting it to numeric and replacing values outside the biologically plausible $18-100$ range with $\\text{NaN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "ess_file = \"data/00-raw/Epworth_Sleepiness_Scale_12Nov2025.csv\"\n",
    "status_file = \"data/00-raw/Participant_Status_12Nov2025.csv\"\n",
    "remsleep_file = \"data/00-raw/REM_Sleep_Behavior_Disorder_Questionnaire_12Nov2025.csv\"\n",
    "\n",
    "# 1. Load the datasets\n",
    "ess_df = pd.read_csv(ess_file)\n",
    "status_df = pd.read_csv(status_file)\n",
    "remsleep_df = pd.read_csv(remsleep_file)\n",
    "\n",
    "# Define target columns\n",
    "status_cols = ['PATNO', 'ENROLL_AGE', 'COHORT', 'COHORT_DEFINITION', \n",
    "               'ENRLPINK1', 'ENRLPRKN', 'ENRLSRDC', 'ENRLNORM', \n",
    "               'ENRLOTHGV', 'ENRLHPSM', 'ENRLRBD', 'ENRLLRRK2', \n",
    "               'ENRLSNCA', 'ENRLGBA']\n",
    "ess_score_cols = [f'ESS{i}' for i in range(1, 9)]\n",
    "ess_cols = ['PATNO'] + ess_score_cols\n",
    "rbd_symptom_cols = ['SLPDSTRB', 'DRMVIVID', 'MVAWAKEN']\n",
    "remsleep_cols = ['PATNO'] + rbd_symptom_cols\n",
    "\n",
    "# --- Process Participant Status Data (Demographics & Genetics) ---\n",
    "\n",
    "# Select only the required columns\n",
    "status_df_focused = status_df[status_cols].copy()\n",
    "\n",
    "# Clean ENROLL_AGE: Convert to numeric and handle outliers\n",
    "status_df_focused['ENROLL_AGE'] = pd.to_numeric(status_df_focused['ENROLL_AGE'], errors='coerce')\n",
    "status_df_focused.loc[~status_df_focused['ENROLL_AGE'].between(18, 100), 'ENROLL_AGE'] = np.nan\n",
    "status_df_cleaned = status_df_focused # Preserve NaNs here to keep all PATNOs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning and Aggregating Longitudinal Data (ESS and RBD)\n",
    "\n",
    "The $\\text{ESS}$ and $\\text{RBD}$ questionnaires are longitudinal (multiple entries per $\\text{PATNO}$). They were cleaned separately to ensure valid scores before aggregation.\n",
    "1. Outlier and Missing Data Handling: For both datasets, score/symptom columns were converted to numeric, and values outside the valid ranges (ESS: $0-3$; RBD symptoms: $0-1$) were replaced with $\\text{NaN}$.\n",
    "2. Total Score Calculation: A total score was calculated for each questionnaire ($\\text{ESS\\_TOTAL}$ and $\\text{RBD\\_SYMPTOMS\\_TOTAL}$). The skipna=False argument was critical here: if a single component score was missing ($\\text{NaN}$), the total score was also set to $\\text{NaN}$.\n",
    "3. Data Integrity: All rows with a resulting $\\text{NaN}$ total score (indicating incomplete or invalid visit data) were dropped to maintain the integrity of the score metrics.\n",
    "4. Aggregation: The cleaned data was grouped by $\\text{PATNO}$, and the mean of the total scores ($\\text{ESS\\_TOTAL\\_MEAN}$ and $\\text{RBD\\_SYMPTOMS\\_MEAN}$) across all valid visits was calculated for each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process ESS Data (Sleepiness Metrics) ---\n",
    "ess_df_focused = ess_df[ess_cols].copy()\n",
    "ess_df_focused[ess_score_cols] = ess_df_focused[ess_score_cols].apply(pd.to_numeric, errors='coerce')\n",
    "for col in ess_score_cols:\n",
    "    ess_df_focused.loc[~ess_df_focused[col].between(0, 3), col] = np.nan\n",
    "ess_df_focused['ESS_TOTAL'] = ess_df_focused[ess_score_cols].sum(axis=1, skipna=False)\n",
    "ess_df_cleaned = ess_df_focused.dropna(subset=ess_score_cols)\n",
    "ess_aggregated = ess_df_cleaned.groupby('PATNO')['ESS_TOTAL'].mean().reset_index(name='ESS_TOTAL_MEAN')\n",
    "\n",
    "# --- Process RBD Data (Select Sleep Quality Metrics) ---\n",
    "remsleep_df_focused = remsleep_df[remsleep_cols].copy()\n",
    "remsleep_df_focused[rbd_symptom_cols] = remsleep_df_focused[rbd_symptom_cols].apply(pd.to_numeric, errors='coerce')\n",
    "for col in rbd_symptom_cols:\n",
    "    remsleep_df_focused.loc[~remsleep_df_focused[col].between(0, 1), col] = np.nan\n",
    "remsleep_df_focused['RBD_SYMPTOMS_TOTAL'] = remsleep_df_focused[rbd_symptom_cols].sum(axis=1, skipna=False)\n",
    "remsleep_df_cleaned = remsleep_df_focused.dropna(subset=rbd_symptom_cols)\n",
    "remsleep_aggregated = remsleep_df_cleaned.groupby('PATNO')['RBD_SYMPTOMS_TOTAL'].mean().reset_index(name='RBD_SYMPTOMS_MEAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Merge and Save\n",
    "\n",
    "The three cleaned and processed tables were merged using a left merge on $\\text{PATNO}$, starting with the patient status data to ensure all unique patient records were preserved, even if they had no valid sleep data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'status_df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge Status (key) with ESS and RBD aggregated scores (left merge)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[43mstatus_df_cleaned\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(ess_aggregated, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPATNO\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m final_df \u001b[38;5;241m=\u001b[39m final_df\u001b[38;5;241m.\u001b[39mmerge(remsleep_aggregated, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPATNO\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save Final Processed Data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'status_df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge Status (key) with ESS and RBD aggregated scores (left merge)\n",
    "final_df = status_df_cleaned.merge(ess_aggregated, on='PATNO', how='left')\n",
    "final_df = final_df.merge(remsleep_aggregated, on='PATNO', how='left')\n",
    "\n",
    "# Save Final Processed Data\n",
    "output_dir = \"data/02-processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "final_output_file = os.path.join(output_dir, \"focused_patient_data.csv\")\n",
    "final_df.to_csv(final_output_file, index=False)\n",
    "final_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Merging Steps\n",
    "\n",
    "- Summary of Data Cleaning & Processing Steps\n",
    "1. Variable Selection: We started with the massive raw NACC dataset (potentially 2,000+ columns) and filtered it down to a targeted subset of ~56 variables. These variables were chosen based on our hypothesis to capture:\n",
    "    - Predictors: Sleep metrics (NPI-Q, Mayo Sleep Questionnaire, SCOPA-Sleep).\n",
    "    - Outcomes: Clinical diagnoses (AD, LBD, PD), cognitive scores (MMSE, MoCA), and biomarkers (CSF, Autopsy).\n",
    "    - Covariates: Demographics, genetics (APOE), and medical history.\n",
    "2. \"Junk Code\" Cleaning: The NACC dataset uses specific integers to represent missing or inapplicable data. We replaced the following codes with NaN (Not a Number) to prevent statistical errors, these are:\n",
    "    - -4: Not available / form not submitted.\n",
    "    - 9, 99, 999: Unknown.\n",
    "    - 8, 88: Not applicable / Not assessed.\n",
    "    - Note: Applied this replacement only to numeric columns as needed to avoid breaking text identifiers like NACCID.\n",
    "3. Cohort Filtering (Row Selection): To test our specific hypothesis, we filtered the participants to include only three distinct groups:\n",
    "    - Alzheimer's: Primary Etiology (NACCETPR) = 1.\n",
    "    - Lewy Body / Parkinson's: Primary Etiology (NACCETPR) = 2.\n",
    "    - Normal Controls: Cognitive Status (COGSTAT) = 2.\n",
    "    - Note: This step automatically excluded participants with Frontotemporal Dementia (FTD) or other primary causes to reduce noise and cloud analyses with differing biomarkers\n",
    "\n",
    "- Through feature engineering, we were able to create a single, clean Diagnosis column to label these three groups (Alzheimers, Lewy Body / PD, Normal Control). This makes plotting and statistical comparison with techniques like ANOVA, clustering, and regression much easier.\n",
    "- Through type conversion, we converted categorical variables (like SEX, RACE, NACCAPOE) from integers into categorical types (factors) so Python treats them as groups rather than numbers, without breaking text identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NACCETPR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NACCETPR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m\n\u001b[1;32m     48\u001b[0m     analysis_data[col] \u001b[38;5;241m=\u001b[39m analysis_data[col]\u001b[38;5;241m.\u001b[39mreplace(junk_codes, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 5. Filter Rows: Keep AD, LBD/PD, and Normal Controls\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Logic: Keep if Primary Diagnosis is AD (1), LBD (2), OR if Cognitive Status is Normal (2)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m analysis_data \u001b[38;5;241m=\u001b[39m analysis_data[\n\u001b[0;32m---> 53\u001b[0m     (\u001b[43manalysis_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNACCETPR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m|\u001b[39m \n\u001b[1;32m     54\u001b[0m     (analysis_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNACCETPR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m|\u001b[39m \n\u001b[1;32m     55\u001b[0m     (analysis_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOGSTAT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     56\u001b[0m ]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# 6. Create the clean 'Diagnosis' column\u001b[39;00m\n\u001b[1;32m     59\u001b[0m conditions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     60\u001b[0m     analysis_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNACCETPR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     61\u001b[0m     analysis_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNACCETPR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     62\u001b[0m     analysis_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOGSTAT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     63\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NACCETPR'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "# Replace 'NACC_data.csv' with the actual path to your file if it's different\n",
    "my_data = pd.read_csv(r'data/NACC_data.csv')\n",
    "\n",
    "# 2. Define the \"Shopping List\" of variables to keep\n",
    "variables_to_keep = [\n",
    "    # Identifiers\n",
    "    \"NACCID\", \"VISITYR\", \"NACCETPR\", \n",
    "    \n",
    "    # Demographics & Covariates\n",
    "    \"NACCAGE\", \"SEX\", \"EDUC\", \"RACE\", \"NACCINCM\",\n",
    "    \"NACCAPOE\", \"NACCNE4S\", \"FADMOM\", \"FADPOP\",\n",
    "    \"TOBAC30\", \"SMOKYRS\", \"ALCOHOL\", \"NACCACT\",\n",
    "    \"CVHATT\", \"CVAFIB\", \"CVCHF\", \"CVSTROKE\", \"DIABETES\", \"DEPRS\",\n",
    "    \n",
    "    # Sleep Metrics (Predictors)\n",
    "    \"NPIQINF\", \"NITE\", \"HYPOSOM\", \"RBD\", \n",
    "    \"LBSPDRM\", \"LBSPTALK\", \"LBSPMOVE\", \"LBSCDRM\",\n",
    "    \"CONSFALL\", \"CONSWKOF\", \"CONSLYAW\", \"CONSWKER\", \"CONSLTTL\", \"CODSAWDY\",\n",
    "    \n",
    "    # Outcomes (Diagnoses & Scores)\n",
    "    \"COGSTAT\", \"NACCALZD\", \"PARK\", \"NACCLBDS\", \"FTD\",\n",
    "    \"NACCMMSE\", \"NACCMOCA\",\n",
    "    \n",
    "    # Motor Exams (UPDRS)\n",
    "    \"LBUMSPCH\", \"LBUMFACE\", \"LBUMREST\", \"LBUMACT\", \"LBUMRIG\", \n",
    "    \"LBUMFALL\", \"LBUMGAIT\", \"LBUMPOST\", \"LBUMBRAD\",\n",
    "    \n",
    "    # Biomarkers\n",
    "    \"NACCACSF\", \"NACCPCSF\", \"NACCTCSF\", \"NACCLEWY\", \"NPLBOD\"\n",
    "]\n",
    "\n",
    "# 3. Create the analysis dataframe\n",
    "# We intersect the list with columns that actually exist to avoid errors\n",
    "existing_vars = [col for col in variables_to_keep if col in my_data.columns]\n",
    "analysis_data = my_data[existing_vars].copy()\n",
    "\n",
    "# 4. Clean \"Junk\" Codes\n",
    "# Replace -4, 8, 9, etc. with NaN (only in numeric columns)\n",
    "junk_codes = [-4, 8, 9, 88, 99, 999]\n",
    "\n",
    "# Iterate over numeric columns and replace junk codes\n",
    "numeric_cols = analysis_data.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    analysis_data[col] = analysis_data[col].replace(junk_codes, np.nan)\n",
    "\n",
    "# 5. Filter Rows: Keep AD, LBD/PD, and Normal Controls\n",
    "# Logic: Keep if Primary Diagnosis is AD (1), LBD (2), OR if Cognitive Status is Normal (2)\n",
    "analysis_data = analysis_data[\n",
    "    (analysis_data['NACCETPR'] == 1) | \n",
    "    (analysis_data['NACCETPR'] == 2) | \n",
    "    (analysis_data['COGSTAT'] == 2)\n",
    "].copy()\n",
    "\n",
    "# 6. Create the clean 'Diagnosis' column\n",
    "conditions = [\n",
    "    analysis_data['NACCETPR'] == 1,\n",
    "    analysis_data['NACCETPR'] == 2,\n",
    "    analysis_data['COGSTAT'] == 2\n",
    "]\n",
    "choices = ['Alzheimers', 'Lewy Body / PD', 'Normal Control']\n",
    "\n",
    "analysis_data['Diagnosis'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "# 7. Convert categorical columns to 'category' type (Factor equivalent)\n",
    "categorical_cols = [\n",
    "    \"SEX\", \"RACE\", \"NACCAPOE\", \"NACCNE4S\", \"TOBAC30\", \"ALCOHOL\",\n",
    "    \"CVHATT\", \"CVAFIB\", \"CVCHF\", \"DIABETES\", \"NPIQINF\", \"NITE\", \"HYPOSOM\", \"RBD\",\n",
    "    \"LBSPDRM\", \"LBSPMOVE\", \"LBSCDRM\", \"CONSFALL\", \"CONSWKOF\", \"CONSLYAW\", \n",
    "    \"CONSWKER\", \"CONSLTTL\", \"CODSAWDY\", \"COGSTAT\", \"NACCALZD\", \"PARK\", \n",
    "    \"NACCLBDS\", \"FTD\", \"NACCLEWY\", \"NPLBOD\", \"Diagnosis\"\n",
    "]\n",
    "\n",
    "# Only convert columns that actually exist in the filtered data\n",
    "existing_cat_cols = [col for col in categorical_cols if col in analysis_data.columns]\n",
    "analysis_data[existing_cat_cols] = analysis_data[existing_cat_cols].astype('category')\n",
    "\n",
    "# The final check: \n",
    "print(\"Final Data Dimensions:\", analysis_data.shape) # dimensions of dataframe\n",
    "print(\"\\nCounts per Diagnosis Group:\")\n",
    "print(analysis_data['Diagnosis'].value_counts())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(analysis_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "If we were to give out a survey to students at UCSD or other adults, we would ask for their consent on whether or not they would like to give out personal details such as how much sleep they have had or any history with neurodegenerative diseases. A consent form for each of the surveys would ensure that we are not collecting personal information from people who would not like to share it to the public. \n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "To account for biases within the data we collect, we will collect from a multitude of sources and validate the contents of the data collected within each source. If a source does not meet our threshold for the amount of data we need to be able to do effective analysis, then we will not utilize it in our predictions. Additionally, we will attempt to account for any factors such as demographics within the data we collect so that our outcomes are more representative of the entire population. \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    " If we were to collect data from surveys we send out to other students, then we would make the effort to keep the personal information as anonymous as possible so that we could control for factors such as race, gender, or any other determining factors. We will only collect relevant data that helps us answer our research question.\n",
    "\n",
    " - [] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [ ] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    " All data collected and the analysis done to this data will be freely available to our entire team and the course staff. It is up to the course staff’s discretion on whether our project and its contents are able to be seen by third parties. As our main sources of information are found through the internet, the data has already been made publicly available, so we are only sharing information that has already been shared by other projects. \n",
    "\n",
    "### C. Analysis\n",
    " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "We have considered the possibility of biased data and we will try to guarantee that we will not view data with prior assumptions, instead we will validate the results alone and make informed predictions about how such data could apply to our goals for the project. To address these biases, we will also be mindful of where our sources come from and also focus only on variables necessary for our project. On the issue of stereotype perpetuation, we will examine our data carefully so that we are not merely looking for causality, but instead taking into account the nuances of degenerative disorders and the people who experience them. \n",
    "\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    " Our graphs and visualizations will be as clear and data driven as possible. We will attempt to minimize the likelihood of our visualizations implying a message that our group did not intend to convey. Underlying data will be explained to ensure that each visualization can not be misinterpreted. We will emphaisize that correlation does not indicate causation and some visualizations will only be serving the purpose of showing relationships between variables and should not be considered as our conclusions about the data being observed. \n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    " We will practice tidy data and clean data wrangling to focus our efforts on the data that directly coincides with the goals of the project. We will omit any data that does not directly affect or relate to the variables we will be analyzing. \n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    " Our data process will be thoroughly documented which will allow anyone in the future to view our project and validate the results of our analysis. Every step from the data wrangling to the visualizations, to all the issues we faced will be written down to describe every process we went through to arrive at our conclusions.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    " Our analysis focuses on sleep-related metrics (ex: sleep duration, sleep apnea events, sleep quality, REM sleep behavior) and clinical data. Using this, and being cautious about including demographic data that could be representative/ a proxy for certain protected characteristics, our goal is to ensure that any predictive power comes from biological and behavioral factors directly related to sleep and health and not from variables that might introduce societal biases like demographics, ethnicity, age groups, generations, etc. \n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    " With our dataset containing demographic information such as age, sex, or race, we plan to evaluate our model’s performance across these different subgroups, but we will check for disparities like false positive and false negative rates in these key metrics to test the model results for fairness with respect to different demographically affected groups to ensure the predictive analysis has no basis on it. And if our model is significantly less accurate for one compared to another group, in our final report we would document and record this disparate rate and discuss its potential implications on ethics and fairness, even if we can’t fully mitigate it because of its training and ingrained biases systemic in the variables’ relationships within the scope of the project. And another question is evaluating whether or not the model is better with or without those ingrained metrics. \n",
    "\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    " Predicting the risk of neurodegenerative diseases, we won’t rely solely on accuracy as our primary metric, and we will prioritize metrics accounting for the cost of incorrect predictions to optimize for considering the effects of optimizing for our defined metrics with model optimization impacts. Specifically focusing on sensitivity (ability to correctly identify individuals at risk) and specificity (ability to correctly identify individuals NOT at risk) and highlighting the trade-off between the two will help us aim for a balance that avoids incorrect metrics like high false positives with an alarm and missing potential cases like high false negatives too as an additional metric to show effects of model optimization and when it comes to an overextent. We will also consider additional metrics like the F1-score and AUC-ROC and other ML metrics to get a more sophisticated and comprehensive view of model performance. \n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    " Starting with simpler, more transparent models like logistic regression or decision trees to establish a baseline and understand the key predictive features helps with model interpretability before getting into obscure algorithms. Using more complex black-box models like gradient boosting, DL, neural networks, if we plan to employ these types of corresponding techniques to analyze feature importance and explain the model’s predictions then a justification will definitely be more needed because the model isn’t as clear in its results and understandable terms for a decision so more explanation is needed. As a health-related topic, being able to explain why the model made a certain prediction at all times is crucial for trust and understanding in results though. \n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    " In our final report and presentation, we will definitely dedicate specific sections to discuss the limitations of our model and tradeoffs. Including any known biases, demographic-based ingrained predispositions, and flaws in our source data, we can show performance trade-offs we had to make and give a clear statement into what our model identifies as correlations and not casual or misconstrued relationships. Approaching it from an educational and exploratory purpose and perspective also helps in showing the applicability of it to clinical and diagnostic real-world situations. \n",
    "\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    " Our evaluation will consist of testing the model’s data on various more training datasets even after deployment to identify skews in performance execution and see if the model is still working to its fullest capacity. The final performance at the analysis and report will be documented thoroughly, and ongoing monitoring with active predictions can be made using another algorithm to match its predictions from a different approach to uncover any biases that might arise from data changes or incorrect errors as a result too. Having robust evaluation metrics for regular audits and performance monitoring and human review and future impact and biases concept basis through evaluating accuracy, understanding sensitivity tradeoff between false positives and false negatives, maximizing recall (minimizing false negatives) in settings, prioritizing at risk individuals, and also evaluating using the F1-score harmonic mean, other model metrics, and the AUC-ROC curve to compare performances across all thresholds, also cross validation, error analysis, peer review and more are all important for post deployment challenges and model auditing.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    " A mechanism for user harm and a formal redress process include meetings with the primary stakeholders, evaluating product goals and concept drift, insurance policies, and if errors are found in our analysis or conclusions from investigations after user harm, the redress plan will involve acknowledging these mistakes, understanding what went wrong, and documenting the correct approach, fulfilling the educational objective of this mistake, and compensating injury in any medium necessary, all preventing future harms through re-investigation of the model.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    " For rolling back in a live production environment, the stakes are much higher, requiring planned, systematic approaches to minimize disruption. An immediate and reliable rollback mechanism is critical. If the new model starts making erroneous predictions, we can instantly switch traffic fro a poorly performing new model back to the last known stable model version using version control on github from our updates. This ensures the final product can always revert to one free of biases and without erroneous error disparities and harmful results. Shifting production traffic quickly is the perfect solution for this issue in ethics and deployment environments. \n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    " The main foreseeable unintended use and consequence would be misinterpreting our model, used for educational purposes and with its idea having no harm inherently, and its findings as medical advice, as it is educational and experimental only and hasn’t been tested on the medical stories and complexities of health issues in all types of patients despite demographic testing it can’t process a multitude of variables and link them at a time like two different diseases, etc. Stressing the correlational (and possibly more to determine and uncover true relationships that exist) nature of our findings and the model’s limitations to discourage misuse and that correlation does not imply causation in our specified conclusion should be the steps we take the identity and prevent unintended uses and abuses of the model and monitoring it as such after deployment with disclaimers and more factors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* *Show up to all meetings possible and be engaged and contributing*\n",
    "* *Respond to team mates within 24 hours*\n",
    "* *Communicate changes and things that you do / have completed to the rest of the group*\n",
    "* *Consulting with the team before making any big changes or decisions*\n",
    "* *Being open to criticism and feedback.*\n",
    "* *Be respectful of your teammate’s opinions and their time*\n",
    "* *Complete your tasks on time and if you can’t make sure to follow up with the rest of the group letting them know.*\n",
    "* *Resolutions on problems or issues should be solved via group vote or consensus*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your work\n",
    "\n",
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 10/23  |  6 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 10/29  |  8 PM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal; Edit, finalize, and submit proposal | \n",
    "| 10/30  | 6 PM  |  Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 11/06  | 6 PM  |  Import & Wrangle Data ; EDA  | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 11/12  | 8 PM  |  Finalize wrangling/EDA; Begin Analysis | Discuss/edit Analysis; Complete project check-in |\n",
    "| 11/13  | 6 PM  |  Complete analysis| Discuss full project |\n",
    "| 11/20  | 6 PM  |  Draft results/conclusion/discussion | Start Editing Full Project |\n",
    "| 11/26  | 8 PM  |  Revise EDA | Discuss whether the EDA follows all expectations |\n",
    "| 11/27  | 6 PM  |  N/A | Discuss follow up issues and concerns any person has |\n",
    "| 12/04  | 6 PM  |  Have a full Final Draft of the project | Discuss any improvements to be made |\n",
    "| 12/10  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
